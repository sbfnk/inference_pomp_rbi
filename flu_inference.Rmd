---
title: "Investigating an infectious disease outbreak with mathematical models"
output:
  html_document:
    toc: yes
bibliography: flu_inference.bib
---

\newcommand\dist[2]{\mathrm{#1}\left(#2\right)}

This tutorial provides an example of inference using a mathematical model fitted to data from an infectious disease outbreak. It is based on the tutorial on [Iterated filtering: principles and practice](https://kingaa.github.io/sbied/mif/mif.html#building-up-a-picture-of-the-likelihood-surface) by Edward Ionides and Aaron A. King. We demonstrate inference using two different methods (Iterated Filtering and Particle Markov-chain Monte Carlo) using two different R packages (**pomp2** and **rbi**).

The tutorial was produced with **R** version `r getRversion()`, **pomp** version `r packageVersion("pomp")` and **rbi** version `r packageVersion("rbi")` on an Intel Xeon E5-2603 v3 1.6GHz (6-core) CPU and Nvidia Tesla P100 16GB NVLink GPU.

```{r knitr-opts,include=FALSE,purl=FALSE}
library(knitr)
prefix <- "flu"
opts_chunk$set(
  progress=TRUE,
  prompt=FALSE,
  tidy=FALSE,
  highlight=TRUE,
  strip.white=TRUE,
  warning=FALSE,
  message=FALSE,
  error=FALSE,
  echo=TRUE,
  cache=TRUE,
  cache.extra=rand_seed,
  results='markup',
  fig.show='asis',
  size='small',
  fig.path=paste0("figure/",prefix,"-"),
  cache.path=paste0("cache/",prefix,"-"),
  fig.align='center',
  fig.height=4,fig.width=6.83,
  dpi=100,
  dev='png',
  dev.args=list(bg='transparent')
)
options(keep.source=TRUE,encoding="UTF-8")
```
```{r prelims,include=FALSE,purl=TRUE,cache=FALSE}
library(plyr)
library(tidyverse)
library(rbi)
library(rbi.helpers)
library(pomp)
options(stringsAsFactors=FALSE)
stopifnot(packageVersion("pomp")>"2.0.9")
set.seed(557976883)
```

# A boarding school influenza outbreak

We consider fitting a stochastic SIR model to an influenza outbreak in a British boarding school [@Anonymous1978].
Reports consist of the number of children confined to bed for each of the 14 days of the outbreak.
The total number of children at the school was 763, and a total of 512 children spent time away from class.
Only one adult developed influenza-like illness, so adults are omitted from the data and model.
The data are provided with the **pomp** package in the `bsflu` object.
To find out how to install the **pomp** package, read at the [pomp installation instructions](https://kingaa.github.io/pomp/install.html).

```{r intro_load_bbs}
library(pomp)
head(bsflu)
```

# A model for the outbreak

The model we will use is a variation on a basic SIR Markov chain, with state $X(t)=(S(t),I(t),R_1(t),R_2(t),R_3(t))$ giving the numbers of individuals in the susceptible and infectious categories, and three stages of recovery.
The recovery stages, $R_1$, $R_2$ and $R_3$, are all modeled to be non-contagious.
$R_1$ consists of individuals who are bed-confined if they showed symptoms;
$R_2$ consists of individuals who are convalescent if they showed symptoms;
$R_3$ consists of recovered individuals who have returned to school-work if they were symptomatic.
The observation on day $n$ of the observed epidemic (with $t_1$ being 22 January) consists of the numbers of children who are bed-confined and convalescent.
Ten individuals received antibiotics for secondary infections, and they had longer bed-confinement and convalescence times.
Partly for this reason, and because our primary interest is in parameters related to transmission, we'll narrow our focus to the bed-confinement numbers, $B_n$, modeling these as $B_n\sim\dist{Poisson}{\rho R_1(t_n)}$, where $\rho$ is a reporting rate corresponding to the chance an infected boy is symptomatic.

```{r intro_sirr-diagram,echo=FALSE,purl=FALSE,fig.height=3/4,fig.width=9,fig.cap="Model flow diagram."}
library(grid)
vp <- viewport(width=unit(0.95,"npc"),height=unit(0.95,"npc"))
pushViewport(vp)
fs <- 24
grid.rect(x=c(1/6,2/6,3/6,4/6,5/6),y=1/2,width=1/12,height=1,just=c(0.5,0.5),gp=gpar(fill="white",lwd=2))
grid.text(x=c(1/6,2/6,3/6,4/6,5/6),y=1/2,label=c(expression(S),expression(I),expression(R[1]),expression(R[2]),expression(R[3])),gp=gpar(fontface=3,fontsize=fs))
grid.lines(x=c(5/24,7/24),y=1/2,arrow=arrow(length=unit(0.1,"npc")),gp=gpar(lwd=2))
grid.lines(x=c(9/24,11/24),y=1/2,arrow=arrow(length=unit(0.1,"npc")),gp=gpar(lwd=2))
grid.lines(x=c(13/24,15/24),y=1/2,arrow=arrow(length=unit(0.1,"npc")),gp=gpar(lwd=2))
grid.lines(x=c(17/24,19/24),y=1/2,arrow=arrow(length=unit(0.1,"npc")),gp=gpar(lwd=2))
popViewport()
```

The index case for the epidemic was purportedly a boy recently returned from Hong Kong, who was reported to have a transient febrile illness from 15 to 18 January.
It would therefore be reasonable to initialize the epidemic at $t_0=-6$ with $I(t_0)=1$.
This is a little tricky to reconcile with the rest of the data;
for the moment, we avoid this issue by instead initializing with $I(t_0)=1$ at $t_0=0$.
All other individuals are modeled to be initially susceptible.

Our Markov transmission model is that each individual in $S$ transitions to $I$ at rate $\beta\,I(t)/N$;
each individual in $I$ transitions at rate $\mu_I$ to $R_1$.
Subsequently, the individual moves from $R_1$ to $R_2$ at  rate $\mu_{R_1}$, and finally from $R_2$ to $R_3$ at rate $\mu_{R_2}$.
Therefore, $1/\mu_I$ is the mean infectious time prior to bed-confinement; $1/\mu_{R_1}$ is the mean duration of bed-confinement for symptomatic cases;
$1/\mu_{R_2}$ is the mean duration of convalescence for symptomatic cases.
All rates have units $\mathrm{day}^{-1}$. 

This model has limitations and weaknesses, but writing down and fitting a model is a starting point for data analysis, not an end point.
In particular, having fit one model, one should certainly try variations on that model.
For example, one could include a latency period for infections, or one could modify the model to give a better description of the bed-confinement and convalescence processes.

We do not need a representation of $R_3$ since this variable has consequences neither for the dynamics of the state process nor for the data.
Since we are confining ourselves for the present to fitting only the $B_n$ data, we need not track $R_2$.

# Inference using iterated filtering with pomp

We first conduct inference using the IF2 iterated filtering algorithm in **pomp**.
For more information on **pomp**, consult the [pomp website](https://kingaa.github.io/pomp/), which contains plenty of documentation and examples.

We enumerate the state variables ($S$, $I$, $R_1$) and the parameters ($\beta$, $\mu_I$, $\rho$, $\mu_{R_1}$) as follows:

```{r pomp_bsflu_names}
statenames <- c("S","I","R1")
paramnames <- c("Beta","mu_I","mu_R1","rho")
```

In the codes below, we'll refer to the data variables by their names ($B$, $C$), as given in the `bsflu` data-frame:
```{r pomp_obsnames,purl=FALSE}
colnames(bsflu)
```

The model code in **pomp** is

```{r pomp_csnippets_bsflu}
dmeas <- Csnippet("
  lik = dpois(B,rho*R1+1e-6,give_log);
")

rmeas <- Csnippet("
  B = rpois(rho*R1+1e-6);
")

rproc <- Csnippet("
  double N = 763;
  double t1 = rbinom(S,1-exp(-Beta*I/N*dt));
  double t2 = rbinom(I,1-exp(-mu_I*dt));
  double t3 = rbinom(R1,1-exp(-mu_R1*dt));
  S  -= t1;
  I  += t1 - t2;
  R1 += t2 - t3;
")

rinit <- Csnippet("
 S = 762;
 I = 1;
 R1 = 0;
")

toEst <- Csnippet("
 T_Beta = log(Beta);
 T_mu_I = log(mu_I);
 T_rho = logit(rho);
")

fromEst <- Csnippet("
 Beta = exp(T_Beta);
 mu_I = exp(T_mu_I);
 rho = expit(T_rho);
")
```

Note that, in our measurement model, we've added a small positive number ($10^{-6}$) to the expected number of cases to prevent problems if $R_1$ goes to zero.

The `fromEst` and `toEst` C snippets implement parameter transformations that to ensure positivity.

Now we build the `pomp` object:

```{r pomp_bsflu}
library(plyr)
library(tidyverse)
library(pomp)

bsflu %>%
  select(day,B) %>%
  pomp(
    times="day",t0=0,
    rmeasure=rmeas,
    dmeasure=dmeas,
    rprocess=euler(rproc,delta.t=1/12),
    rinit=rinit,
    partrans=parameter_trans(fromEst=fromEst,toEst=toEst),
    statenames=statenames,
    paramnames=paramnames
  ) -> flu
```
```{r pomp_bsflu_plot,purl=F}
plot(flu,main="")
```

## Testing the codes

To develop and debug code, it is useful to have testing codes that run quickly and fail if the codes are not working correctly.
As such a test, here we run some simulations and a particle filter.
We'll use the following parameters:
```{r pomp_start_params}
params <- c(Beta=2,mu_I=1,rho=0.9,mu_R1=1/3,mu_R2=1/2)
```

Now to run and plot some simulations:
```{r pomp_init_sim}
flu %>% simulate(params=params,nsim=10,format="data.frame") -> y
```
```{r pomp_init_sim_plot,purl=F}
theme_set(theme_bw())

y %>%
  ggplot(aes(x=day,y=B,group=.id))+
  geom_line()
```

Before engaging in iterated filtering, it is a good idea to check that the basic particle filter is working since iterated filtering builds on this technique.
The simulations above check the `rprocess` and `rmeasure` codes;
the particle filter depends on the `rprocess` and `dmeasure` codes and so is a check of the latter.

```{r pomp_init_pfilter}
flu %>% pfilter(params=params,Np=1000) -> pf
```
```{r pomp_init_pfilter_plot,purl=F,fig.width=4,fig.height=6}
plot(pf)
```

The above plot shows the data (`B`), along with the *effective sample size* of the particle filter (`ess`) and the log likelihood of each observation conditional on the preceding ones (`cond.logLik`).

## Setting up the estimation problem

Let's treat $\mu_{R_1}$ and  $\mu_{R_2}$ as known, and fix these parameters at the empirical means of the bed-confinement and convalescence times for symptomatic cases, respectively:

```{r pomp_fixed_params}
with(bsflu,c(mu_R1=1/(sum(B)/512),mu_R2=1/(sum(C)/512))) -> fixed_params
fixed_params
```

We will estimate $\beta$, $\mu_I$, and $\rho$.

It will be helpful to parallelize most of the computations.
Most machines nowadays have multiple cores and using this computational capacity is as simple as:

i. letting **R** know you plan to use multiple processors;
i. using the parallel for loop provided by the **foreach** package; and
i. paying proper attention to the use of parallel random number generators.

For example:

```{r pomp_parallel_setup,cache=FALSE}
library(foreach)
library(doParallel)
registerDoParallel()
```

The first two lines above load the **foreach** and **doParallel** packages, the latter being a "backend" for the **foreach** package.
The next line tells **foreach** that we will use the **doParallel** backend.
By default, **R** will guess how many cores are available and will run about half this number of concurrent **R** processes.

## Running a particle filter

We proceed to carry out replicated particle filters at an initial guess of $\beta=2$, $\mu_I=1$, and $\rho=0.9$.

```{r pomp_pf}
library(doRNG)
registerDoRNG(625904618)
bake(file="pf.rds",{
  foreach(i=1:10,.packages='pomp',
    .export=c("flu","fixed_params")
  ) %dopar% {
    flu %>% pfilter(params=c(Beta=2,mu_I=1,rho=0.9,fixed_params),Np=10000)
  }
}) -> pf
(L_pf <- logmeanexp(sapply(pf,logLik),se=TRUE))
```

In `r round(attr(pf,"system.time")["elapsed"],2)` seconds, using `r min(getDoParWorkers(),length(pf))` cores, we obtain an unbiased likelihood estimate of `r round(L_pf[1],1)` with a Monte Carlo standard error of `r signif(L_pf[2],2)`.

## Building up a picture of the likelihood surface

Given a model and a set of data, the likelihood surface is well defined, though it may be difficult to visualize.
We can develop a progressively more complete picture of this surface by storing likelihood estimates whenever we compute them.
In particular, it is a very good idea to set up a database within which to store the likelihood of every point for which we have an estimated likelihood.
This will become larger and more complete as our parameter-space search goes on and will be a basis for a variety of explorations.
At this point, we've computed the likelihood at a single point.
Let's store this point, together with the estimated likelihood and our estimate of the standard error on that likelihood, in a CSV file:
```{r pomp_init_csv}
results <- as.data.frame(as.list(c(coef(pf[[1]]),loglik=L_pf[1],loglik=L_pf[2])))
write.csv(results,file="bsflu_params.csv",row.names=FALSE)
```

## A local search of the likelihood surface

Let's carry out a local search using `mif2` around this point in parameter space. 
To do so, we need to choose the `rw.sd` and `cooling.fraction.50` algorithmic parameters.
Since $\beta$ and $\mu_I$ will be estimated on the log scale, and we expect that multiplicative perturbations of these parameters will have roughly similar effects on the likelihood, we'll use a perturbation size of $0.02$, which we imagine will have a small but non-negligible effect.
For simplicity, we'll use the same perturbation size on $\rho$.
We fix `cooling.fraction.50=0.5`, so that after 50 `mif2` iterations, the perturbations are reduced to half their original magnitudes.

```{r pomp_box_search_local}
registerDoRNG(482947940)
bake(file="box_search_local.rds",{
  foreach(i=1:20,
    .packages='pomp',
    .combine=c, 
    .export=c("flu","fixed_params")
  ) %dopar%  
  {
    flu %>%
    mif2(
      params=c(Beta=2,mu_I=1,rho=0.9,fixed_params),
      Np=2000,
      Nmif=50,
      cooling.fraction.50=0.5,
      rw.sd=rw.sd(Beta=0.02,mu_I=0.02,rho=0.02)
    )
  }
}) -> mifs_local
```

We obtain some diagnostic plots with the `plot` command applied to `mifs_local`.
Here is a way to get a prettier version:

```{r pomp_box_search_local_plot,purl=FALSE}
mifs_local %>%
  traces() %>%
  melt() %>%
  ggplot(aes(x=iteration,y=value,group=L1,color=factor(L1)))+
  geom_line()+
  guides(color=FALSE)+
  facet_wrap(~variable,scales="free_y")+
  theme_bw()
```

No filtering failures (`nfail`) are generated at any point, which is comforting.
In general, we expect to see filtering failures whenever our initial guess (`start`) is incompatible with one or more of the observations.
Filtering failures at the maximum-likelihood estimate (MLE) are an indication that the model, at its best, is incompatible with one or more of the data.

We see that the likelihood generally increases as the iterations proceed, though there is considerable variability due to the stochastic nature of this Monte Carlo algorithm.
Although the filtering carried out by `mif2` in the final filtering iteration generates an approximation to the likelihood at the resulting point estimate, this is not usually good enough for reliable inference.
Partly, this is because parameter perturbations are applied in the last filtering iteration, so that the likelihood shown here is not identical to that of the model of interest.
Partly, this is because `mif2` is usually carried out with fewer particles than are needed for a good likelihood evaluation:
the errors in `mif2` average out over many iterations of the filtering.
Therefore, we evaluate the likelihood, together with a standard error, using replicated particle filters at each point estimate:

```{r pomp_lik_local}
registerDoRNG(900242057)
bake(file="lik_local.rds",{
  foreach(mf=mifs_local,.packages='pomp',.combine=rbind) %dopar% 
  {
    evals <- replicate(10, logLik(pfilter(mf,Np=20000)))
    ll <- logmeanexp(evals,se=TRUE)
    c(coef(mf),loglik=ll[1],loglik=ll[2])
  }
}) -> results_local
```
```{r pomp_t_local, include=FALSE,purl=FALSE}
t_local <- attr(results_local,"system.time")
```
```{r pomp_results_local}
results_local <- as.data.frame(results_local)
```

This investigation took `r round(attr(mifs_local,"system.time")["elapsed"],0)` seconds for the maximization and `r round(t_local["elapsed"],0)` seconds for the likelihood evaluation.
These repeated stochastic maximizations can also show us the geometry of the likelihood surface in a neighborhood of this point estimate:

```{r pomp_pairs_local,purl=FALSE}
pairs(~loglik+Beta+mu_I+rho,data=results_local,pch=16)
```

Although this plot some hints of ridges in the likelihood surface (cf. the $\beta$-$\mu_I$ panel), the sampling is still too sparse to give a clear picture.

We add these newly explored points to our database:
```{r pomp_local_database}
results <- rbind(results,results_local[names(results)])
write.csv(results,file="bsflu_params.csv",row.names=FALSE)
```

## A global search of the likelihood surface using randomized starting values

When carrying out parameter estimation for dynamic systems, we need to specify beginning values for both the dynamic system (in the state space) and the parameters (in the parameter space).
To avoid confusion, we use the term "initial values" to refer to the state of the system at $t_0$ and "starting values" to refer to the point in parameter space at which a search is initialized.

Practical parameter estimation involves trying many starting values for the parameters.
One way to approach this is to choose a large box in parameter space that contains all remotely sensible parameter vectors.
If an estimation method gives stable conclusions with starting values drawn randomly from this box, this gives some confidence that an adequate global search has been carried out. 

For our flu model, a box containing reasonable parameter values might be

```{r pomp_box_global}
params_box <- rbind(
  Beta=c(1,5),
  mu_I=c(0.5,3),
  rho = c(0.5,1)
)
```

We are now ready to carry out likelihood maximizations from diverse starting points.

```{r pomp_box_search_global}
registerDoRNG(1270401374)
guesses <- as.data.frame(apply(params_box,1,function(x)runif(300,x[1],x[2])))
mf1 <- mifs_local[[1]]
bake(file="box_search_global.rds",{
  foreach(guess=iter(guesses,"row"), 
    .packages='pomp', 
    .combine=rbind,
    .export=c("mf1","fixed_params")
  ) %dopar% 
  {
    mf1 %>%
      mif2(params=c(unlist(guess),fixed_params)) %>%
      mif2(Nmif=100) -> mf
    ll <- replicate(10,mf %>% pfilter(Np=100000) %>% logLik())
    ll <- logmeanexp(ll,se=TRUE)
    c(coef(mf),loglik=ll[1],loglik=ll[2])
  }
}) -> results_global
```
```{r pomp_t_global,purl=FALSE,include=FALSE}
t_global <- attr(results_global,"system.time")
```
```{r pomp_results_global}
results_global <- as.data.frame(results_global)
results <- rbind(results,results_global[names(results)])
write.csv(results,file="bsflu_params.csv",row.names=FALSE)
```
The above codes run one search from each of `r nrow(guesses)` starting values.
Each search consists of an initial run of `r nrow(traces(mf1))` IF2 iterations, followed by another 100 iterations.
These codes exhibit a general **pomp** behavior:
re-running a command on an object (i.e., `mif2` on `mf1`) created by the same command preserves the algorithmic arguments.
In particular, running `mif2` on the result of a `mif2` computation re-runs IF2 from the endpoint of the first run.
In the second computation, by default, all algorithmic parameters are preserved;
here we overrode the default choice of `Nmif`.

Following the `mif2` computations, the particle filter is used to evaluate the likelihood, as before.
In contract to the local-search codes above, here we return only the endpoint of the search, together with the likelihood estimate and its standard error in a named vector.
The best result of this search had a likelihood of `r round(max(results_global$loglik),1)` with a standard error of `r round(results_global$loglik.se[which.max(results_global$loglik)],2)`.
This took `r round(t_global["elapsed"]/60,1)` minutes altogether.

Again, we attempt to visualize the global geometry of the likelihood surface using a scatterplot matrix.
In particular, here we plot both the starting values (grey) and the IF2 estimates (red).

```{r pomp_pairs_global,purl=FALSE}

list(
  guess=guesses,
  result=subset(results, loglik > max(loglik)-50)
) %>%
  ldply(.id="type") -> all

pairs(~loglik+Beta+mu_I+rho, data=all, col=ifelse(all$type=="guess", grey(0.5), "red"), pch=16)
```

We see that optimization attempts from diverse remote starting points converge on a particular region in parameter space.
Moreover, the estimates have comparable likelihoods, despite their considerable variability.
This gives us some confidence in our maximization procedure. 

# Inference using pMCMC with rbi

We next conduct inference using the same model and the same dataset, but this time using particle Markov-chain Monte Carlo (pMCMC) using the **rbi** package.
For details on how to install **rbi** and the required **LibBi** library, please visit the [rbi github page](https://github.com/sbfnk/rbi).
For more details on **rbi**, consult the [introductory vignette](https://cran.r-project.org/web/packages/rbi/vignettes/introduction.html), and for an introduction to **LibBi** the corresponding [article in the Journal of Statistical Software](http://dx.doi.org/10.18637/jss.v067.i10).

We first load the necessary libraries

```{r rbi_init,cache=FALSE}
library(rbi)
library(rbi.helpers)
library(stringi) ## for reading the model from a string
library(pomp) ## for the bsflu data set
library(tidyverse)

set.seed(296825852)
```

Next, we formulate the model

```{r rbi_model}
model_str <- '
  model bsflu {
    const N = 763
    const timestep = 1/12

    param Beta, mu_I, mu_R1, rho
    state S, I, R1

    noise infection, recovery, leave_bed

    obs Incidence

    sub parameter {
      Beta ~ uniform(1, 5)
      mu_I ~ uniform(0.5, 3)
      rho ~ uniform(0.5, 1)
    }

    sub initial {
      S <- N - 1 // susceptibles
      I <- 1     // infectious
      R1 <- 1    // recovered but bed-confined
    }

    sub transition (delta = timestep) {
      infection ~ binomial(S, 1 - exp(-Beta * I/N * timestep))
      recovery ~ binomial(I, 1 - exp(-mu_I * timestep))
      leave_bed ~ binomial(R1, 1 - exp(-mu_R1 * timestep))

      S <- S - infection
      I <- I + infection - recovery
      R1 <- R1 + recovery - leave_bed
    }

    sub observation {
      Incidence ~ poisson(rho * R1 + 1e-6)
    }
  }
'
```

The character variable `model_str` contains the model as it is read by **LibBi**.
First the variables are defined.
Constants are defined using `const`, parameters (i.e., variables that do not vary over time) using `param`, states (i.e., variables that vary over time) using `state`, random variables using `noise` and observation variables using `obs`.
In the `parameter` block, the prior distributions of the free parameters are specified.
The `initial` block sets the initial values for state variables, and the `transition` block specifies the transition densities.
The `observation` block encodes the observation process.
For details on this, consult the [LibBi Manual](http://libbi.org/docs/LibBi-Manual.pdf).

To read in the model to be used with **LibBi**, we create a `bi_model` object,
```{r rbi_init_bi_model}
flu_model <- bi_model(lines = stri_split_lines(model_str)[[1]]) %>%
    fix(mu_R1 = 1/(sum(bsflu$B)/512))
```
where we have also fixed the value of `mu_R1` as in the pomp example.

We then prepare the `bsflu` variable for use with **LibBi**.
To pass observations (or any other data), we need to generate a list of data frames, each element of which has a name corresponding to the variable name in **LibBi**.
Each data frame needs to have a `time` and a `value` column.
To convert the observations into this format, we use

```{r rbi_convert_obs}
obs <- bsflu %>%
    select(time=date, value=B) %>%
    list(Incidence=.) %>%
    time_to_numeric(origin=as.Date("1978-01-21"), unit="day")
```

Lastly, we create a `libbi` object, that we can use to run the model and conduct inference:

```{r rbi_create_libbi}
bi <- libbi(model=flu_model, obs=obs, end_time=nrow(bsflu))
```

If an NVidia GPU is available, it can be used in the following codes by passing `cuda=TRUE` to the `libbi` command (in which case it applies to all subsequent calls to libbi), or to any of the following commands (see [below](#rbi_gpu)).

## Testing the codes

As with the **pomp** example, we start with testing the model syntax and running some simulations.
To check whether there are any errors in the model, one can use the `rewrite` command:

```{r rbi_rewrite, eval=FALSE}
  rewrite(bi)
```

This returns the model as translated internally by **LibBi**.
If this command returns an error, there is a problem with the model syntax somewhere.
One can always view the model with line numbers by just displaying the variable contents.

```{r rbi_echo_model, results='hide'}
  flu_model
``` 

We now run some simulations and a particle filter.

```{r rbi_sim_bi}
params <- c(Beta=2,mu_I=1,rho=0.9,mu_R1=1/3,mu_R2=1/2)
sim <- rbi::simulate(bi, init=as.list(params), nsamples=10)
```

This will take a few moments as **LibBi** will compile the model for faster execution later.
Note that we passed the same parameters used in the earlier pomp example, passed using `init` and again as a named list.
To plot the simulations, we first read them in using `bi_read`

```{r rbi_sim_plot}
sim_res <- bi_read(sim, type="state")
ggplot(sim_res$R1, aes(x=time, group=np))+
    geom_line(aes(y=value)) +
    ylab("R1")
```

We also check that the particle filter is working. 

```{r rbi_pfilter}
filtered <-  rbi::filter(sim, nparticles=1000)
filter_R1 <- summary(filtered, type="state") %>%
  dplyr::filter(var=="R1")
ggplot(filter_R1, aes(x=time))+
    geom_line(aes(y=Median)) +
    geom_ribbon(aes(ymin=`1st Qu.`, ymax=`3rd Qu.`), alpha=0.5) +
    geom_point(aes(y=value), obs$Incidence, color="darkred") +
    ylab("R1")
```

The plot shows the median filtered trajectory (black line) and interquartile range (grey ribbon), as well as the data (red dots).

## Preparing for MCMC

Before running pMCMC, it is worth considering how many particles one should use. 
A commonly used rule of thumb is to choose the number of particles such that the variance of the likelihood estimate is approximately one.
This can be tested using the `adapt_particles` function contained in the `rbi.helpers` package:

```{r rbi_adapt_particles}
particles_adapted <- bi %>%
  sample(proposal="prior", nsamples=2000, nparticles=1024) %>% 
  adapt_particles(max=2**20)
nparticles <- particles_adapted$options$nparticles 
nparticles
```

This starts with 1024 particles and first generates 2000 samples proposing from the prior to have a reasonably good location in parameter space to test the number of particles needed.
Then, the `adapt_particles` function scales up the number of particles until the variance of the likelihood estimate crosses one.
This function can take a while to run as the runs will take longer with increasing number of particles.
In our case, the optimal number of particles found is `r format(nparticles, scientific=FALSE)`.

We also need to determine a suitable proposal distribution for running MCMC.
To do this, we can use the `adapt_proposal` function contained in the `rbi.helpers` package.
This, once again, does a series of test runs and adapts the proposal distribution after every run using the empirical covariance of accepted samples.

```{r rbi_adapt_proposal, message=FALSE}
proposal_adapted <- particles_adapted %>%
    sample(proposal="prior", nsamples=2000) %>% 
    adapt_proposal(min=0.1, max=0.3, adapt="both")
```

In this case, the proposal distribution is adapted to yield an acceptance rate between 0.1 and 0.3.

## Running pMCMC

We proceed to run full particle Markov chain Monte Carlo (pMCMC) to generate 10,000 samples from the posterior distributionn.

```{r rbi_posterior}
posterior <- proposal_adapted %>%
    sample(nsamples=10000)
```

```{r rbi_posterior_minutes, echo=FALSE}
cpu_minutes <- round(bi_read(posterior)$clock/1e+6/60)
```

Generating the samples took `r cpu_minutes` minutes.

We can plot the filtered trajectories from the posterior distribution,
```{r rbi_posterior_trajectories}
posterior_obs <- sample_obs(posterior)
incidence <- summary(posterior_obs, type="obs")
ggplot(incidence, aes(x=time)) +
  geom_line(aes(y=Median)) +
  geom_ribbon(aes(ymin=`1st Qu.`, ymax=`3rd Qu.`), alpha=0.5) +
  geom_point(aes(y=value), obs$Incidence, color="darkred") +
  ylab("Incidence")
```
parameter traces
```{r rbi_posterior_traces}
traces <- get_traces(posterior)
library(ggmcmc)
library(coda)
S <- ggs(mcmc(traces))
ggs_traceplot(S)
```
and correlations
```{r rbi_posterior_pairs}
library(GGally)
ggpairs(traces)
```

## GPU acceleration {#rbi_gpu}

If an Nvidia GPU is available and CUDA installed, it is possible to accelerate the computations significantly.
To test if you have a GPU available, one can use the `gpuR` package

```{r test_gpu, eval=FALSE}
library(gpuR)
listContexts()
```

If this yields a platform that contains "CUDA" somewhere, an Nvidia GPU is available.
In this case, one can make any of the `rbi` commands use the GPU by adding `cuda=TRUE`, e.g.

```{r rbi_posterior_cuda}
posterior <- proposal_adapted %>%
  sample(nsamples=10000, cuda=TRUE)
```

```{r rbi_posterior_cuda_minutes, echo=FALSE}
gpu_minutes <- round(bi_read(posterior)$clock/1e+6/60)
```

Using the GPU, generating 10,000 samples took `r gpu_minutes` minutes.

## pMCMC in pomp

The *pomp* package also implements pMCMC.
To run this, we need to define a prior distribution.
We can do this in the same way as before using a Csnippet.

```{r pomp_prior_prior}
priorDens <- "
  lik = dunif(Beta, 1, 5, 1)+
        dunif(mu_I, 0.5, 3, 1)+
        dunif(rho, 0.5, 1, 1);
        if (!give_log) lik = exp(lik);
"
```

We can then run MCMC starting with one of the locally searched parameters from earlier as a starting point.

```{r pomp_pmcmc_start, include=FALSE}
start <- Sys.time()
```

```{r pomp_pmcmc}
pmcmc(pomp(mifs_local[[1]], dprior=Csnippet(priorDens),
      paramnames=c("Beta","mu_I","rho")),
      Nmcmc = 10000, Np = nparticles,
      proposal = mvn.rw.adaptive(rw.sd=c(Beta=0.4, mu_I=0.25, rho=0.05),
                                 scale.start=100, shape.start=500, scale.cooling=0.99)) -> pmh
```

```{r pomp_pmcmc_end, include=FALSE}
end <- Sys.time()
```

Generating the 10,000 samples with **pomp** took `r as.integer(round(difftime(end, start, units='mins')))` minutes.

# References
